{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from transformers import AutoModel, PreTrainedTokenizerFast, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "lr = 1e-3\n",
    "epoch = 10\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' 特别感动，我为什么不用这票钱去吃东西',\n",
       "  ' 画面美好 意境留足 孤独感萦绕 配音不出戏 很好',\n",
       "  ' 卧槽，复活快银好么？！彩蛋是灭霸',\n",
       "  ' 宿命轮回，有因必有果 画风很美，后期略有些仓促，值得推荐一看 为中国传统文化打五星',\n",
       "  '  好看！美队身材真好😂钢铁侠感觉像个逗比，雷神一出现我还以为布拉德皮特-_-#黑寡妇也是很sexy，最后几位大神团结在一块杀妖魔鬼怪的时候蛮感动的 最后想说IMAX效果好棒，老美这大片拍的已然无法超越😐',\n",
       "  ' 改编的还是照样喜欢！喜欢就没差咯！漫威大法好好好！旺达好美好美！',\n",
       "  ' 什么乱七八糟的内容？畸形的价值观，自私的女主角，为了所谓的报恩连累整个村，三角恋的恋情设计得一塌糊涂，台词让我数次起尴尬症，有模仿千与千寻的痕迹，可连它的百分之一都比不上，给一星是因为无法打零分！',\n",
       "  ' 配乐是日本人做的，原画是中传学生画的，后期是外包给韩国人的，做了十二年拿着众筹的钱去旅游是主办方做的，宣传是打着中国版千与千寻的噱头卖情怀的，最后说一句，剧情是玛丽苏的，我还能说些什么？',\n",
       "  ' 真的没想到，这个片子这么烂，这么脑残，太拉低老外的智商了吧 ',\n",
       "  ' 重要的不是电影而是陪在你身边的人 坐第一排仰着脖子看也可以那么舒心',\n",
       "  ' 大鱼一生黑 粉丝行为，电影买单 ',\n",
       "  ' 画外音，不错哦，对白有点幼稚，其他都蛮好！',\n",
       "  ' 漫威的忠实观众，从大一开始看他们的漫画和电影！挺不错的',\n",
       "  ' 玛丽苏苏的我一脸血，感想就不说了，因为实在无话可说，我尴尬癌犯了让我歇会儿',\n",
       "  ' “我们一定会再相遇的，相信我”“相信我，跟我一起跳，相信我”“我会化作人间的风雨，陪着你……”谁说这是狗血三角恋我打死谁……到最后简直哭成狗……这明明就是一个纯到不行的爱、勇气与自我实现的故事 ',\n",
       "  ' 一个绿茶婊的故事 悲催的男二号 '),\n",
       " tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./comments.bin\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "n = int(len(data) * 0.8)\n",
    "train_ds = data[:n].values.tolist()\n",
    "val_ds = data[n:].values.tolist()\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_model_path, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(pretrained_model_path)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # 特征提取 使用正常lr = 1e-3\n",
    "        # 全量微调 使用较小lr = le-5 ~ 1e-4\n",
    "        with torch.no_grad():\n",
    "            # bert\n",
    "            result = self.bert(input_ids, attention_mask, token_type_ids)\n",
    "        # classifier\n",
    "        output = self.classifier(result.pooler_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = \"./pretrained_models/roberta_dianping\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./pretrained_models/roberta_dianping\")\n",
    "model = BertClassifier(pretrained_model_path, 2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryWarpper:\n",
    "    def __init__(self):\n",
    "        self.writer = SummaryWriter(\"logs\")\n",
    "        self.train_cnt = 0\n",
    "        self.val_cnt = 0\n",
    "\n",
    "    def train_loss(self, func):\n",
    "        \n",
    "        def warpper(loss_fn, logits, y):\n",
    "            loss = func(loss_fn, logits, y)\n",
    "            self.writer.add_scalar(\"Train Loss\", loss, self.train_cnt)\n",
    "            self.train_cnt += 1\n",
    "            return loss\n",
    "            pass\n",
    "        return warpper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_loss = SummaryWarpper()\n",
    "@sw_loss.train_loss\n",
    "def train_loss(loss_fn, logits, y):\n",
    "    loss = loss_fn(logits, y)\n",
    "    return loss\n",
    "\n",
    "def train(model, tokenizer, loss_fn, optimizer, train_data, val_data, epoch, device):\n",
    "    model = model.to(device)\n",
    "    print(device)\n",
    "    for e in range(epoch):\n",
    "        bar = tqdm(train_data)\n",
    "        for X, y in bar:\n",
    "            X = tokenizer(X, return_tensors=\"pt\", padding=True)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(**X)\n",
    "            loss = train_loss(loss_fn, logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            bar.set_description(f\"epoch:{e + 1}, train loss:{loss.item():.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:1, train loss:0.1782: 100%|██████████| 1000/1000 [00:33<00:00, 30.15it/s]\n",
      "epoch:2, train loss:0.2412: 100%|██████████| 1000/1000 [00:30<00:00, 32.51it/s]\n",
      "epoch:3, train loss:0.2947: 100%|██████████| 1000/1000 [00:30<00:00, 33.24it/s]\n",
      "epoch:4, train loss:0.4041: 100%|██████████| 1000/1000 [00:31<00:00, 31.60it/s]\n",
      "epoch:5, train loss:0.1441: 100%|██████████| 1000/1000 [00:30<00:00, 32.75it/s]\n",
      "epoch:6, train loss:0.1184: 100%|██████████| 1000/1000 [00:30<00:00, 32.89it/s]\n",
      "epoch:7, train loss:0.1146: 100%|██████████| 1000/1000 [00:30<00:00, 32.28it/s]\n",
      "epoch:8, train loss:0.2306: 100%|██████████| 1000/1000 [00:30<00:00, 32.79it/s]\n",
      "epoch:9, train loss:0.1975: 100%|██████████| 1000/1000 [00:32<00:00, 30.97it/s]\n",
      "epoch:10, train loss:0.1859: 100%|██████████| 1000/1000 [00:32<00:00, 30.85it/s]\n"
     ]
    }
   ],
   "source": [
    "train(model, tokenizer, loss_fn, optimizer, train_dl, val_dl, epoch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input, device):\n",
    "    model = model.to(device)\n",
    "    X = tokenizer(input, return_tensors=\"pt\", padding=True).to(device)\n",
    "    logits = model(**X)\n",
    "    y_hat = logits.argmax(-1)\n",
    "    print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"这里的货质量真的很好。\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
