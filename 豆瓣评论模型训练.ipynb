{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from transformers import AutoModel, PreTrainedTokenizerFast, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "lr = 1e-3\n",
    "epoch = 10\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ç‰¹åˆ«æ„ŸåŠ¨ï¼Œæˆ‘ä¸ºä»€ä¹ˆä¸ç”¨è¿™ç¥¨é’±å»åƒä¸œè¥¿',\n",
       "  ' ç”»é¢ç¾å¥½ æ„å¢ƒç•™è¶³ å­¤ç‹¬æ„Ÿè¦ç»• é…éŸ³ä¸å‡ºæˆ å¾ˆå¥½',\n",
       "  ' å§æ§½ï¼Œå¤æ´»å¿«é“¶å¥½ä¹ˆï¼Ÿï¼å½©è›‹æ˜¯ç­éœ¸',\n",
       "  ' å®¿å‘½è½®å›ï¼Œæœ‰å› å¿…æœ‰æœ ç”»é£å¾ˆç¾ï¼ŒåæœŸç•¥æœ‰äº›ä»“ä¿ƒï¼Œå€¼å¾—æ¨èä¸€çœ‹ ä¸ºä¸­å›½ä¼ ç»Ÿæ–‡åŒ–æ‰“äº”æ˜Ÿ',\n",
       "  '  å¥½çœ‹ï¼ç¾é˜Ÿèº«æçœŸå¥½ğŸ˜‚é’¢é“ä¾ æ„Ÿè§‰åƒä¸ªé€—æ¯”ï¼Œé›·ç¥ä¸€å‡ºç°æˆ‘è¿˜ä»¥ä¸ºå¸ƒæ‹‰å¾·çš®ç‰¹-_-#é»‘å¯¡å¦‡ä¹Ÿæ˜¯å¾ˆsexyï¼Œæœ€åå‡ ä½å¤§ç¥å›¢ç»“åœ¨ä¸€å—æ€å¦–é­”é¬¼æ€ªçš„æ—¶å€™è›®æ„ŸåŠ¨çš„ æœ€åæƒ³è¯´IMAXæ•ˆæœå¥½æ£’ï¼Œè€ç¾è¿™å¤§ç‰‡æ‹çš„å·²ç„¶æ— æ³•è¶…è¶ŠğŸ˜',\n",
       "  ' æ”¹ç¼–çš„è¿˜æ˜¯ç…§æ ·å–œæ¬¢ï¼å–œæ¬¢å°±æ²¡å·®å’¯ï¼æ¼«å¨å¤§æ³•å¥½å¥½å¥½ï¼æ—ºè¾¾å¥½ç¾å¥½ç¾ï¼',\n",
       "  ' ä»€ä¹ˆä¹±ä¸ƒå…«ç³Ÿçš„å†…å®¹ï¼Ÿç•¸å½¢çš„ä»·å€¼è§‚ï¼Œè‡ªç§çš„å¥³ä¸»è§’ï¼Œä¸ºäº†æ‰€è°“çš„æŠ¥æ©è¿ç´¯æ•´ä¸ªæ‘ï¼Œä¸‰è§’æ‹çš„æ‹æƒ…è®¾è®¡å¾—ä¸€å¡Œç³Šæ¶‚ï¼Œå°è¯è®©æˆ‘æ•°æ¬¡èµ·å°´å°¬ç—‡ï¼Œæœ‰æ¨¡ä»¿åƒä¸åƒå¯»çš„ç—•è¿¹ï¼Œå¯è¿å®ƒçš„ç™¾åˆ†ä¹‹ä¸€éƒ½æ¯”ä¸ä¸Šï¼Œç»™ä¸€æ˜Ÿæ˜¯å› ä¸ºæ— æ³•æ‰“é›¶åˆ†ï¼',\n",
       "  ' é…ä¹æ˜¯æ—¥æœ¬äººåšçš„ï¼ŒåŸç”»æ˜¯ä¸­ä¼ å­¦ç”Ÿç”»çš„ï¼ŒåæœŸæ˜¯å¤–åŒ…ç»™éŸ©å›½äººçš„ï¼Œåšäº†åäºŒå¹´æ‹¿ç€ä¼—ç­¹çš„é’±å»æ—…æ¸¸æ˜¯ä¸»åŠæ–¹åšçš„ï¼Œå®£ä¼ æ˜¯æ‰“ç€ä¸­å›½ç‰ˆåƒä¸åƒå¯»çš„å™±å¤´å–æƒ…æ€€çš„ï¼Œæœ€åè¯´ä¸€å¥ï¼Œå‰§æƒ…æ˜¯ç›ä¸½è‹çš„ï¼Œæˆ‘è¿˜èƒ½è¯´äº›ä»€ä¹ˆï¼Ÿ',\n",
       "  ' çœŸçš„æ²¡æƒ³åˆ°ï¼Œè¿™ä¸ªç‰‡å­è¿™ä¹ˆçƒ‚ï¼Œè¿™ä¹ˆè„‘æ®‹ï¼Œå¤ªæ‹‰ä½è€å¤–çš„æ™ºå•†äº†å§ ',\n",
       "  ' é‡è¦çš„ä¸æ˜¯ç”µå½±è€Œæ˜¯é™ªåœ¨ä½ èº«è¾¹çš„äºº åç¬¬ä¸€æ’ä»°ç€è„–å­çœ‹ä¹Ÿå¯ä»¥é‚£ä¹ˆèˆ’å¿ƒ',\n",
       "  ' å¤§é±¼ä¸€ç”Ÿé»‘ ç²‰ä¸è¡Œä¸ºï¼Œç”µå½±ä¹°å• ',\n",
       "  ' ç”»å¤–éŸ³ï¼Œä¸é”™å“¦ï¼Œå¯¹ç™½æœ‰ç‚¹å¹¼ç¨šï¼Œå…¶ä»–éƒ½è›®å¥½ï¼',\n",
       "  ' æ¼«å¨çš„å¿ å®è§‚ä¼—ï¼Œä»å¤§ä¸€å¼€å§‹çœ‹ä»–ä»¬çš„æ¼«ç”»å’Œç”µå½±ï¼æŒºä¸é”™çš„',\n",
       "  ' ç›ä¸½è‹è‹çš„æˆ‘ä¸€è„¸è¡€ï¼Œæ„Ÿæƒ³å°±ä¸è¯´äº†ï¼Œå› ä¸ºå®åœ¨æ— è¯å¯è¯´ï¼Œæˆ‘å°´å°¬ç™ŒçŠ¯äº†è®©æˆ‘æ­‡ä¼šå„¿',\n",
       "  ' â€œæˆ‘ä»¬ä¸€å®šä¼šå†ç›¸é‡çš„ï¼Œç›¸ä¿¡æˆ‘â€â€œç›¸ä¿¡æˆ‘ï¼Œè·Ÿæˆ‘ä¸€èµ·è·³ï¼Œç›¸ä¿¡æˆ‘â€â€œæˆ‘ä¼šåŒ–ä½œäººé—´çš„é£é›¨ï¼Œé™ªç€ä½ â€¦â€¦â€è°è¯´è¿™æ˜¯ç‹—è¡€ä¸‰è§’æ‹æˆ‘æ‰“æ­»è°â€¦â€¦åˆ°æœ€åç®€ç›´å“­æˆç‹—â€¦â€¦è¿™æ˜æ˜å°±æ˜¯ä¸€ä¸ªçº¯åˆ°ä¸è¡Œçš„çˆ±ã€å‹‡æ°”ä¸è‡ªæˆ‘å®ç°çš„æ•…äº‹ ',\n",
       "  ' ä¸€ä¸ªç»¿èŒ¶å©Šçš„æ•…äº‹ æ‚²å‚¬çš„ç”·äºŒå· '),\n",
       " tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./comments.bin\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "n = int(len(data) * 0.8)\n",
    "train_ds = data[:n].values.tolist()\n",
    "val_ds = data[n:].values.tolist()\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=True)\n",
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, pretrained_model_path, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(pretrained_model_path)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # ç‰¹å¾æå– ä½¿ç”¨æ­£å¸¸lr = 1e-3\n",
    "        # å…¨é‡å¾®è°ƒ ä½¿ç”¨è¾ƒå°lr = le-5 ~ 1e-4\n",
    "        with torch.no_grad():\n",
    "            # bert\n",
    "            result = self.bert(input_ids, attention_mask, token_type_ids)\n",
    "        # classifier\n",
    "        output = self.classifier(result.pooler_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = \"./pretrained_models/roberta_dianping\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./pretrained_models/roberta_dianping\")\n",
    "model = BertClassifier(pretrained_model_path, 2)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryWarpper:\n",
    "    def __init__(self):\n",
    "        self.writer = SummaryWriter(\"logs\")\n",
    "        self.train_cnt = 0\n",
    "        self.val_cnt = 0\n",
    "\n",
    "    def train_loss(self, func):\n",
    "        \n",
    "        def warpper(loss_fn, logits, y):\n",
    "            loss = func(loss_fn, logits, y)\n",
    "            self.writer.add_scalar(\"Train Loss\", loss, self.train_cnt)\n",
    "            self.train_cnt += 1\n",
    "            return loss\n",
    "            pass\n",
    "        return warpper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_loss = SummaryWarpper()\n",
    "@sw_loss.train_loss\n",
    "def train_loss(loss_fn, logits, y):\n",
    "    loss = loss_fn(logits, y)\n",
    "    return loss\n",
    "\n",
    "def train(model, tokenizer, loss_fn, optimizer, train_data, val_data, epoch, device):\n",
    "    model = model.to(device)\n",
    "    print(device)\n",
    "    for e in range(epoch):\n",
    "        bar = tqdm(train_data)\n",
    "        for X, y in bar:\n",
    "            X = tokenizer(X, return_tensors=\"pt\", padding=True)\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(**X)\n",
    "            loss = train_loss(loss_fn, logits, y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            bar.set_description(f\"epoch:{e + 1}, train loss:{loss.item():.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch:1, train loss:0.1782: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:33<00:00, 30.15it/s]\n",
      "epoch:2, train loss:0.2412: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:30<00:00, 32.51it/s]\n",
      "epoch:3, train loss:0.2947: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:30<00:00, 33.24it/s]\n",
      "epoch:4, train loss:0.4041: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:31<00:00, 31.60it/s]\n",
      "epoch:5, train loss:0.1441: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:30<00:00, 32.75it/s]\n",
      "epoch:6, train loss:0.1184: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:30<00:00, 32.89it/s]\n",
      "epoch:7, train loss:0.1146: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:30<00:00, 32.28it/s]\n",
      "epoch:8, train loss:0.2306: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:30<00:00, 32.79it/s]\n",
      "epoch:9, train loss:0.1975: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:32<00:00, 30.97it/s]\n",
      "epoch:10, train loss:0.1859: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:32<00:00, 30.85it/s]\n"
     ]
    }
   ],
   "source": [
    "train(model, tokenizer, loss_fn, optimizer, train_dl, val_dl, epoch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input, device):\n",
    "    model = model.to(device)\n",
    "    X = tokenizer(input, return_tensors=\"pt\", padding=True).to(device)\n",
    "    logits = model(**X)\n",
    "    y_hat = logits.argmax(-1)\n",
    "    print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "predict(model, \"è¿™é‡Œçš„è´§è´¨é‡çœŸçš„å¾ˆå¥½ã€‚\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
